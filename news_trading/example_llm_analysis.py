# -*- coding: utf-8 -*-
"""
32GB VRAM í•˜ì´ë¸Œë¦¬ë“œ LLM ë‰´ìŠ¤ ë¶„ì„ ì˜ˆì œ

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” FinancialHybridLLMì„ ì‚¬ìš©í•˜ì—¬
ê¸ˆìœµ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

ì‚¬ì „ ìš”êµ¬ì‚¬í•­:
1. Ollama ì„¤ì¹˜ ë° ì‹¤í–‰ (ollama serve)
2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ:
   - ollama pull ingu627/exaone4.0:32b
   - ollama pull qwen3:8b
   - fin-r1 (GGUF ë³€í™˜ í•„ìš”)

ì‹¤í–‰:
    python example_llm_analysis.py
"""

import logging
import sys

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, '.')

from modules.llm import FinancialHybridLLM


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger(__name__)

    print("=" * 60)
    print("32GB VRAM í•˜ì´ë¸Œë¦¬ë“œ LLM ë‰´ìŠ¤ ë¶„ì„ ì˜ˆì œ")
    print("=" * 60)

    # í•˜ì´ë¸Œë¦¬ë“œ LLM ì´ˆê¸°í™”
    try:
        llm = FinancialHybridLLM(
            api_url="http://localhost:11434",
            enable_parallel=True,
            timeout=120
        )
        print("\nâœ… LLM ì´ˆê¸°í™” ì™„ë£Œ")
    except ConnectionError as e:
        print(f"\nâŒ Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        print("   'ollama serve' ëª…ë ¹ì–´ë¡œ Ollamaë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    # í…ŒìŠ¤íŠ¸ ë‰´ìŠ¤ ëª©ë¡
    test_news = [
        {
            "title": "ì‚¼ì„±ì „ì, 3ë¶„ê¸° ì˜ì—…ì´ìµ 10ì¡° ì› ëŒíŒŒ...HBM ìˆ˜ìš” ê¸‰ì¦",
            "stock_code": "005930",
            "expected": "POSITIVE"
        },
        {
            "title": "SKí•˜ì´ë‹‰ìŠ¤, ç¾ ë°˜ë„ì²´ ìˆ˜ì¶œ ê·œì œ ê°•í™”ì— ì£¼ê°€ ê¸‰ë½",
            "stock_code": "000660",
            "expected": "NEGATIVE"
        },
        {
            "title": "í˜„ëŒ€ì°¨, ì „ê¸°ì°¨ íŒë§¤ëŸ‰ ì „ë…„ ëŒ€ë¹„ 15% ì¦ê°€",
            "stock_code": "005380",
            "expected": "POSITIVE"
        },
        {
            "title": "ì¹´ì¹´ì˜¤, ì„ì‹œ ì£¼ì£¼ì´íšŒ ê°œìµœ ì˜ˆì •...ê²½ì˜ì§„ ì¸ì‚¬ ë³€ë™ ì˜ˆê³ ",
            "stock_code": "035720",
            "expected": "NEUTRAL"
        },
        {
            "title": "LGì—ë„ˆì§€ì†”ë£¨ì…˜, ç¾ ì• ë¦¬ì¡°ë‚˜ ê³µì¥ ì°©ê³µ...1ì¡°ì› íˆ¬ì",
            "stock_code": "373220",
            "expected": "POSITIVE"
        }
    ]

    print("\n" + "-" * 60)
    print("ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘")
    print("-" * 60)

    results = []

    for i, news in enumerate(test_news, 1):
        print(f"\n[{i}/{len(test_news)}] ë¶„ì„ ì¤‘...")
        print(f"ğŸ“° ë‰´ìŠ¤: {news['title']}")
        print(f"ğŸ¢ ì¢…ëª©: {news['stock_code']}")

        # ë¶„ì„ ìˆ˜í–‰
        result = llm.analyze(
            news_title=news["title"],
            stock_code=news["stock_code"]
        )

        results.append({
            "news": news,
            "result": result
        })

        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
        print(f"   â€¢ ìµœì¢… ê°ì„±: {result.final_sentiment.value.upper()}")
        print(f"   â€¢ ì‹ ë¢°ë„: {result.final_confidence:.1%}")
        print(f"   â€¢ ì˜í–¥ë„: {result.final_impact.value}")
        print(f"   â€¢ ëª¨ë¸ í•©ì˜ë„: {result.consensus_score:.1%}")
        print(f"   â€¢ ë§¤ë§¤ ì¶”ì²œ: {result.recommendation}")

        # ê°œë³„ ëª¨ë¸ ê²°ê³¼
        if result.individual_results:
            print(f"\n   [ê°œë³„ ëª¨ë¸ ë¶„ì„]")
            for r in result.individual_results:
                print(f"   â€¢ {r.model_source}: {r.sentiment.value} "
                      f"({r.confidence:.0%}) - {r.reasoning[:40]}...")

    # ìš”ì•½
    print("\n" + "=" * 60)
    print("ë¶„ì„ ìš”ì•½")
    print("=" * 60)

    for item in results:
        news = item["news"]
        result = item["result"]
        match = "âœ…" if result.final_sentiment.value == news["expected"].lower() else "âŒ"

        print(f"\n{match} {news['title'][:30]}...")
        print(f"   ì˜ˆìƒ: {news['expected']}, ê²°ê³¼: {result.final_sentiment.value.upper()}, ì¶”ì²œ: {result.recommendation}")

    # ëª¨ë¸ ìƒíƒœ í™•ì¸
    print("\n" + "-" * 60)
    print("ëª¨ë¸ ìƒíƒœ")
    print("-" * 60)
    status = llm.get_model_status()
    print(f"ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸: {len(status['running_models'])}ê°œ")
    print(f"ì´ VRAM ì‚¬ìš©ëŸ‰: {status['total_vram_used']:.1f} GB")


if __name__ == "__main__":
    main()
